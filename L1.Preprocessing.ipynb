{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ML-Challenge/week5-preprocessing-and-tunning/blob/master/L1.Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson covers the basics of how and when to perform data preprocessing. This essential step in any machine learning project is when we get our data ready for modeling. Between importing and cleaning the data and fitting the machine learning model is when preprocessing comes into play. We'll learn how to standardize the data so that it's in the right form for the model, create new features to best leverage the information in the dataset, and select the best features to improve the model fit. Finally, we'll have some practice preprocessing by getting a dataset on UFO sightings ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.017074Z",
     "start_time": "2020-02-16T17:50:51.009105Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Download lesson datasets\n",
    "# Required if you're using Google Colab\n",
    "#!wget \"https://github.com/ML-Challenge/week5-preprocessing-and-tunning/raw/master/datasets.zip\"\n",
    "#!unzip -o datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.541783Z",
     "start_time": "2020-02-16T17:50:51.048543Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import utils\n",
    "# We'll be using this module throughout the lesson\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.759200Z",
     "start_time": "2020-02-16T17:50:51.544741Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# and setting the size of all plots.\n",
    "plt.rcParams['figure.figsize'] = [11, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we'll learn exactly what it means to `preprocess` data. We'll take the first steps in any preprocessing journey, including exploring data types and dealing with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset comprised of volunteer information from New York City. The dataset has a number of features, but we want to get rid of features that have at least 3 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many features are in the original dataset, and how many features are in the set after columns with at least 3 missing values are removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.790117Z",
     "start_time": "2020-02-16T17:50:51.761197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 665 entries, 0 to 664\n",
      "Data columns (total 35 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   opportunity_id      665 non-null    int64  \n",
      " 1   content_id          665 non-null    int64  \n",
      " 2   vol_requests        665 non-null    int64  \n",
      " 3   event_time          665 non-null    int64  \n",
      " 4   title               665 non-null    object \n",
      " 5   hits                665 non-null    object \n",
      " 6   summary             665 non-null    object \n",
      " 7   is_priority         62 non-null     object \n",
      " 8   category_id         617 non-null    float64\n",
      " 9   category_desc       665 non-null    object \n",
      " 10  amsl                0 non-null      float64\n",
      " 11  amsl_unit           0 non-null      float64\n",
      " 12  org_title           665 non-null    object \n",
      " 13  org_content_id      665 non-null    int64  \n",
      " 14  addresses_count     665 non-null    int64  \n",
      " 15  locality            595 non-null    object \n",
      " 16  region              665 non-null    object \n",
      " 17  postalcode          659 non-null    float64\n",
      " 18  primary_loc         0 non-null      float64\n",
      " 19  display_url         665 non-null    object \n",
      " 20  recurrence_type     665 non-null    object \n",
      " 21  hours               665 non-null    int64  \n",
      " 22  created_date        665 non-null    object \n",
      " 23  last_modified_date  665 non-null    object \n",
      " 24  start_date_date     665 non-null    object \n",
      " 25  end_date_date       665 non-null    object \n",
      " 26  status              665 non-null    object \n",
      " 27  Latitude            0 non-null      float64\n",
      " 28  Longitude           0 non-null      float64\n",
      " 29  Community Board     0 non-null      float64\n",
      " 30  Community Council   0 non-null      float64\n",
      " 31  Census Tract        0 non-null      float64\n",
      " 32  BIN                 0 non-null      float64\n",
      " 33  BBL                 0 non-null      float64\n",
      " 34  NTA                 0 non-null      float64\n",
      "dtypes: float64(13), int64(7), object(15)\n",
      "memory usage: 182.0+ KB\n"
     ]
    }
   ],
   "source": [
    "utils.volunteer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.821037Z",
     "start_time": "2020-02-16T17:50:51.792110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 665 entries, 0 to 664\n",
      "Data columns (total 24 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   opportunity_id      665 non-null    int64  \n",
      " 1   content_id          665 non-null    int64  \n",
      " 2   vol_requests        665 non-null    int64  \n",
      " 3   event_time          665 non-null    int64  \n",
      " 4   title               665 non-null    object \n",
      " 5   hits                665 non-null    object \n",
      " 6   summary             665 non-null    object \n",
      " 7   is_priority         62 non-null     object \n",
      " 8   category_id         617 non-null    float64\n",
      " 9   category_desc       665 non-null    object \n",
      " 10  org_title           665 non-null    object \n",
      " 11  org_content_id      665 non-null    int64  \n",
      " 12  addresses_count     665 non-null    int64  \n",
      " 13  locality            595 non-null    object \n",
      " 14  region              665 non-null    object \n",
      " 15  postalcode          659 non-null    float64\n",
      " 16  display_url         665 non-null    object \n",
      " 17  recurrence_type     665 non-null    object \n",
      " 18  hours               665 non-null    int64  \n",
      " 19  created_date        665 non-null    object \n",
      " 20  last_modified_date  665 non-null    object \n",
      " 21  start_date_date     665 non-null    object \n",
      " 22  end_date_date       665 non-null    object \n",
      " 23  status              665 non-null    object \n",
      "dtypes: float64(2), int64(7), object(15)\n",
      "memory usage: 124.8+ KB\n"
     ]
    }
   ],
   "source": [
    "volunteer_clean = utils.volunteer.dropna(axis=1, thresh=3)\n",
    "volunteer_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the `volunteer` dataset again, we want to drop rows where the `category_desc` column values are missing. We're going to do this using boolean indexing, by checking to see if we have any null values, and then filtering the dataset so that we only have rows with those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.835989Z",
     "start_time": "2020-02-16T17:50:51.823031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check how many values are missing in the category_desc column\n",
    "print(utils.volunteer['category_desc'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.850949Z",
     "start_time": "2020-02-16T17:50:51.837958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset the volunteer dataset\n",
    "volunteer_subset = utils.volunteer[utils.volunteer['category_desc'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.865912Z",
     "start_time": "2020-02-16T17:50:51.851946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 35)\n"
     ]
    }
   ],
   "source": [
    "# Print out the shape of the subset\n",
    "print(volunteer_subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you can use boolean indexing to effectively subset DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking another look at the dataset comprised of volunteer information from New York City, we want to know what types we'll be working with as we start to do more preprocessing. Which data types are present in the volunteer dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.881871Z",
     "start_time": "2020-02-16T17:50:51.868876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opportunity_id          int64\n",
       "content_id              int64\n",
       "vol_requests            int64\n",
       "event_time              int64\n",
       "title                  object\n",
       "hits                   object\n",
       "summary                object\n",
       "is_priority            object\n",
       "category_id           float64\n",
       "category_desc          object\n",
       "amsl                  float64\n",
       "amsl_unit             float64\n",
       "org_title              object\n",
       "org_content_id          int64\n",
       "addresses_count         int64\n",
       "locality               object\n",
       "region                 object\n",
       "postalcode            float64\n",
       "primary_loc           float64\n",
       "display_url            object\n",
       "recurrence_type        object\n",
       "hours                   int64\n",
       "created_date           object\n",
       "last_modified_date     object\n",
       "start_date_date        object\n",
       "end_date_date          object\n",
       "status                 object\n",
       "Latitude              float64\n",
       "Longitude             float64\n",
       "Community Board       float64\n",
       "Community Council     float64\n",
       "Census Tract          float64\n",
       "BIN                   float64\n",
       "BBL                   float64\n",
       "NTA                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have int, float and object (string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a column type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the `volunteer` dataset types, we'll see that the column hits is type object. But, if we actually look at the column, we'll see that it consists of integers. Let's convert that column to type int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.896826Z",
     "start_time": "2020-02-16T17:50:51.883836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    737\n",
      "1     22\n",
      "2     62\n",
      "3     14\n",
      "4     31\n",
      "Name: hits, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the hits column\n",
    "print(utils.volunteer[\"hits\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use astype to convert between a variety of types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.912783Z",
     "start_time": "2020-02-16T17:50:51.898796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the hits column to type int\n",
    "utils.volunteer[\"hits\"] = utils.volunteer[\"hits\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.927751Z",
     "start_time": "2020-02-16T17:50:51.914758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opportunity_id          int64\n",
      "content_id              int64\n",
      "vol_requests            int64\n",
      "event_time              int64\n",
      "title                  object\n",
      "hits                    int32\n",
      "summary                object\n",
      "is_priority            object\n",
      "category_id           float64\n",
      "category_desc          object\n",
      "amsl                  float64\n",
      "amsl_unit             float64\n",
      "org_title              object\n",
      "org_content_id          int64\n",
      "addresses_count         int64\n",
      "locality               object\n",
      "region                 object\n",
      "postalcode            float64\n",
      "primary_loc           float64\n",
      "display_url            object\n",
      "recurrence_type        object\n",
      "hours                   int64\n",
      "created_date           object\n",
      "last_modified_date     object\n",
      "start_date_date        object\n",
      "end_date_date          object\n",
      "status                 object\n",
      "Latitude              float64\n",
      "Longitude             float64\n",
      "Community Board       float64\n",
      "Community Council     float64\n",
      "Census Tract          float64\n",
      "BIN                   float64\n",
      "BBL                   float64\n",
      "NTA                   float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Look at the dtypes of the dataset\n",
    "print(utils.volunteer.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `volunteer` dataset, we're thinking about trying to predict the `category_desc` variable using the other features in the dataset. First, though, we need to know what the class distribution (and imbalance) is for that label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which descriptions occur less than 50 times in the volunteer dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.942710Z",
     "start_time": "2020-02-16T17:50:51.928747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strengthening Communities    333\n",
       "Helping Neighbors in Need    124\n",
       "Education                     98\n",
       "Health                        57\n",
       "Environment                   36\n",
       "Emergency Preparedness        17\n",
       "Name: category_desc, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer['category_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Emergency Prepardness and Environment occur less than 50 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the distribution of variables in the `category_desc` column in the `volunteer` dataset is uneven. If we wanted to train a model to try to predict `category_desc`, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.958661Z",
     "start_time": "2020-02-16T17:50:51.944677Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a data with all columns except category_desc\n",
    "volunteer_X = utils.volunteer.drop('category_desc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:51.974627Z",
     "start_time": "2020-02-16T17:50:51.960631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a category_desc labels dataset\n",
    "volunteer_y = utils.volunteer[['category_desc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.409469Z",
     "start_time": "2020-02-16T17:50:51.976590Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the volunteer_y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.425390Z",
     "start_time": "2020-02-16T17:50:52.411429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    249\n",
      "Helping Neighbors in Need     93\n",
      "Education                     73\n",
      "Health                        43\n",
      "Environment                   27\n",
      "Emergency Preparedness        13\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print out the category_desc counts on the training y labels\n",
    "print(y_train['category_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter is all about standardizing data. Often a model will make some assumptions about the distribution or scale of the features. Standardization is a way to make the data fit these assumptions and improve the algorithm's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to standardize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned when it is appropriate to standardize your data, which of these scenarios would we **NOT** want to standardize?\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "1. A column we want to use for modeling has extremely high variance.\n",
    "2. We have a dataset with several continuous columns on different scales and we'd like to use a linear model to train the data.\n",
    "3. The models we're working with use some sort of distance metric in a linear space, like the Euclidean metric.\n",
    "4. Our dataset is comprised of categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.441348Z",
     "start_time": "2020-02-16T17:50:52.427386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1, 2, 3 or 4 as the answer\n"
     ]
    }
   ],
   "source": [
    "# Use 1,2,3 or 4 as a parameter\n",
    "utils.when_to_standardize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling without normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what might happen to our model's accuracy if we try to model data without doing some sort of standardization first. Here we have a subset of the `wine` dataset. One of the columns, `Proline`, has an extremely high variance compared to the other columns. This is an example of where a technique like log normalization would come in handy, which we'll learn about in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.473305Z",
     "start_time": "2020-02-16T17:50:52.443344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0     1    14.23        1.71  2.43               15.6        127   \n",
       "1     1    13.20        1.78  2.14               11.2        100   \n",
       "2     1    13.16        2.36  2.67               18.6        101   \n",
       "3     1    14.37        1.95  2.50               16.8        113   \n",
       "4     1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.489253Z",
     "start_time": "2020-02-16T17:50:52.476255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a subset of data\n",
    "wine_X = utils.wine[['Proline', 'Total phenols', 'Hue', 'Nonflavanoid phenols']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.505213Z",
     "start_time": "2020-02-16T17:50:52.492212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Type labels dataset\n",
    "wine_y = utils.wine['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.520161Z",
     "start_time": "2020-02-16T17:50:52.507206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_X, wine_y, stratify=wine_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.581002Z",
     "start_time": "2020-02-16T17:50:52.522132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the k-nearest neighbors model to the training data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.596966Z",
     "start_time": "2020-02-16T17:50:52.582971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy score is pretty low. Let's explore methods to improve this score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the variance of the columns in the wine dataset and see which column is a candidate for normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.612914Z",
     "start_time": "2020-02-16T17:50:52.598927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                                0.600679\n",
       "Alcohol                             0.659062\n",
       "Malic acid                          1.248015\n",
       "Ash                                 0.075265\n",
       "Alcalinity of ash                  11.152686\n",
       "Magnesium                         203.989335\n",
       "Total phenols                       0.391690\n",
       "Flavanoids                          0.997719\n",
       "Nonflavanoid phenols                0.015489\n",
       "Proanthocyanins                     0.327595\n",
       "Color intensity                     5.374449\n",
       "Hue                                 0.052245\n",
       "OD280/OD315 of diluted wines        0.504086\n",
       "Proline                         99166.717355\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.wine.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `Proline` column has an extremely high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log normalization in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that the `Proline` column in our wine dataset has a large amount of variance, let's log normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.627876Z",
     "start_time": "2020-02-16T17:50:52.614889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99166.71735542436\n"
     ]
    }
   ],
   "source": [
    "# Print out the variance of the Proline column\n",
    "print(utils.wine['Proline'].var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.642835Z",
     "start_time": "2020-02-16T17:50:52.629870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the log normalization function to the Proline column\n",
    "utils.wine['Proline_log'] = np.log(utils.wine['Proline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.657783Z",
     "start_time": "2020-02-16T17:50:52.645803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17231366191842012\n"
     ]
    }
   ],
   "source": [
    "# Check the variance of the normalized Proline column\n",
    "print(utils.wine['Proline_log'].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.log()` function is an easy way to log normalize a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.673754Z",
     "start_time": "2020-02-16T17:50:52.659765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a subset of data\n",
    "wine_X = utils.wine[['Proline_log', 'Total phenols', 'Hue', 'Nonflavanoid phenols']]\n",
    "\n",
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_X, wine_y, stratify=wine_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.689721Z",
     "start_time": "2020-02-16T17:50:52.675743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.704670Z",
     "start_time": "2020-02-16T17:50:52.691681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling data for feature comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data - investigating columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the `Ash`, `Alcalinity of ash`, and `Magnesium` columns in the wine dataset to train a linear model, but it's possible that these columns are all measured in different ways, which would bias a linear model. Using `describe()` to return descriptive statistics about this dataset, which of the following statements are true about the scale of data in these columns?\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "1. The max of `Ash` is 3.23, the max of `Alcalinity of ash` is 30, and the max of `Magnesium` is 162.\n",
    "2. The means of `Ash` and `Alcalinity of ash` are less than 20, while the mean of `Magnesium` is greater than 90.\n",
    "3. The standard deviations of `Ash` and `Alcalinity of ash` are equal.\n",
    "4. 1 and 2 are true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.767509Z",
     "start_time": "2020-02-16T17:50:52.707638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>6.530303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.415107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>5.627621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>6.215606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>6.512486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>6.892642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>7.426549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Type     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       Proanthocyanins  Color intensity         Hue  \\\n",
       "count       178.000000       178.000000  178.000000   \n",
       "mean          1.590899         5.058090    0.957449   \n",
       "std           0.572359         2.318286    0.228572   \n",
       "min           0.410000         1.280000    0.480000   \n",
       "25%           1.250000         3.220000    0.782500   \n",
       "50%           1.555000         4.690000    0.965000   \n",
       "75%           1.950000         6.200000    1.120000   \n",
       "max           3.580000        13.000000    1.710000   \n",
       "\n",
       "       OD280/OD315 of diluted wines      Proline  Proline_log  \n",
       "count                    178.000000   178.000000   178.000000  \n",
       "mean                       2.611685   746.893258     6.530303  \n",
       "std                        0.709990   314.907474     0.415107  \n",
       "min                        1.270000   278.000000     5.627621  \n",
       "25%                        1.937500   500.500000     6.215606  \n",
       "50%                        2.780000   673.500000     6.512486  \n",
       "75%                        3.170000   985.000000     6.892642  \n",
       "max                        4.000000  1680.000000     7.426549  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data - standardizing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the `Ash`, `Alcalinity of ash`, and `Magnesium` columns in the wine dataset are all on different scales, let's standardize them in a way that allows for use in a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.783466Z",
     "start_time": "2020-02-16T17:50:52.769505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import StandardScaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.798395Z",
     "start_time": "2020-02-16T17:50:52.785463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the scaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.818421Z",
     "start_time": "2020-02-16T17:50:52.802385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a subset of the DataFrame we want to scale \n",
    "wine_subset = utils.wine[['Ash', 'Alcalinity of ash', 'Magnesium']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.833914Z",
     "start_time": "2020-02-16T17:50:52.820924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the scaler to the DataFrame subset\n",
    "wine_subset_scaled = ss.fit_transform(wine_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.865834Z",
     "start_time": "2020-02-16T17:50:52.835887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "      <td>1.780000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-8.370333e-16</td>\n",
       "      <td>-3.991813e-17</td>\n",
       "      <td>-3.991813e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.002821e+00</td>\n",
       "      <td>1.002821e+00</td>\n",
       "      <td>1.002821e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.679162e+00</td>\n",
       "      <td>-2.671018e+00</td>\n",
       "      <td>-2.088255e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.721225e-01</td>\n",
       "      <td>-6.891372e-01</td>\n",
       "      <td>-8.244151e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.382132e-02</td>\n",
       "      <td>1.518295e-03</td>\n",
       "      <td>-1.222817e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.981085e-01</td>\n",
       "      <td>6.020883e-01</td>\n",
       "      <td>5.096384e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.156325e+00</td>\n",
       "      <td>3.154511e+00</td>\n",
       "      <td>4.371372e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Ash  Alcalinity of ash     Magnesium\n",
       "count  1.780000e+02       1.780000e+02  1.780000e+02\n",
       "mean  -8.370333e-16      -3.991813e-17 -3.991813e-17\n",
       "std    1.002821e+00       1.002821e+00  1.002821e+00\n",
       "min   -3.679162e+00      -2.671018e+00 -2.088255e+00\n",
       "25%   -5.721225e-01      -6.891372e-01 -8.244151e-01\n",
       "50%   -2.382132e-02       1.518295e-03 -1.222817e-01\n",
       "75%    6.981085e-01       6.020883e-01  5.096384e-01\n",
       "max    3.156325e+00       3.154511e+00  4.371372e+00"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(wine_subset_scaled, columns=['Ash', 'Alcalinity of ash', 'Magnesium']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, running `fit_transform` during preprocessing will both fit the method to the data as well as transform the data in a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardized data and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on non-scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the accuracy of a K-nearest neighbors model on the `wine` dataset without standardizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.881784Z",
     "start_time": "2020-02-16T17:50:52.867799Z"
    }
   },
   "outputs": [],
   "source": [
    "X = utils.wine.drop(['Type', 'Proline_log'], axis=1)\n",
    "y = utils.wine['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.897755Z",
     "start_time": "2020-02-16T17:50:52.883784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.913708Z",
     "start_time": "2020-02-16T17:50:52.898747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.928669Z",
     "start_time": "2020-02-16T17:50:52.915706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score on the unscaled `wine` dataset was decent, but we can likely do better if we scale the dataset. The process is mostly the same as the previous example, with the added step of scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.944629Z",
     "start_time": "2020-02-16T17:50:52.931630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the scaling method.\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.960576Z",
     "start_time": "2020-02-16T17:50:52.946620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the scaling method to the dataset used for modeling.\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.975514Z",
     "start_time": "2020-02-16T17:50:52.962546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:52.991467Z",
     "start_time": "2020-02-16T17:50:52.977504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in accuracy is worth the extra step of scaling the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we'll learn about feature engineering. We'll explore different ways to create new, more useful, features from the ones already in the dataset. We'll see how to encode, aggregate, and extract information from both numerical and textual features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering knowledge test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned about feature engineering, which of the following examples are good candidates for creating new features?\n",
    "\n",
    "**Possible Answers*\n",
    "\n",
    "1. A column of timestamps\n",
    "2. A column of newspaper headlines\n",
    "3. A column of weight measurements\n",
    "4. 1 and 2\n",
    "5. None of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.022385Z",
     "start_time": "2020-02-16T17:50:53.016403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1, 2, 3, 4 or 5 as the answer\n"
     ]
    }
   ],
   "source": [
    "# Use 1,2,3,4 or 5 as parameter\n",
    "utils.feature_engineering_puzzle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying areas for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an exploratory look at the `volunteer` dataset. Which of the following columns would you want to perform a feature engineering task on?\n",
    "\n",
    "**Posible Answers**\n",
    "\n",
    "1. `vol_requests`\n",
    "2. `title`\n",
    "3. `created_date`\n",
    "4. `category_desc`\n",
    "5. 2,3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.099212Z",
     "start_time": "2020-02-16T17:50:53.067267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>vol_requests</th>\n",
       "      <th>event_time</th>\n",
       "      <th>title</th>\n",
       "      <th>hits</th>\n",
       "      <th>summary</th>\n",
       "      <th>is_priority</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_desc</th>\n",
       "      <th>...</th>\n",
       "      <th>end_date_date</th>\n",
       "      <th>status</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Community Council</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>BBL</th>\n",
       "      <th>NTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4996</td>\n",
       "      <td>37004</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
       "      <td>737</td>\n",
       "      <td>Building on successful events last summer and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008</td>\n",
       "      <td>37036</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Web designer</td>\n",
       "      <td>22</td>\n",
       "      <td>Build a website for an Afghan business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5016</td>\n",
       "      <td>37143</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
       "      <td>62</td>\n",
       "      <td>Please join us and the students from Mott Hall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>37237</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>Fight global hunger and support women farmers ...</td>\n",
       "      <td>14</td>\n",
       "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>March 31 2012</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5055</td>\n",
       "      <td>37425</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Stop 'N' Swap</td>\n",
       "      <td>31</td>\n",
       "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Environment</td>\n",
       "      <td>...</td>\n",
       "      <td>February 05 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   opportunity_id  content_id  vol_requests  event_time  \\\n",
       "0            4996       37004            50           0   \n",
       "1            5008       37036             2           0   \n",
       "2            5016       37143            20           0   \n",
       "3            5022       37237           500           0   \n",
       "4            5055       37425            15           0   \n",
       "\n",
       "                                               title  hits  \\\n",
       "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
       "1                                       Web designer    22   \n",
       "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
       "3  Fight global hunger and support women farmers ...    14   \n",
       "4                                      Stop 'N' Swap    31   \n",
       "\n",
       "                                             summary is_priority  category_id  \\\n",
       "0  Building on successful events last summer and ...         NaN          NaN   \n",
       "1             Build a website for an Afghan business         NaN          1.0   \n",
       "2  Please join us and the students from Mott Hall...         NaN          1.0   \n",
       "3  The Oxfam Action Corps is a group of dedicated...         NaN          1.0   \n",
       "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN          4.0   \n",
       "\n",
       "               category_desc  ...     end_date_date    status Latitude  \\\n",
       "0  Strengthening Communities  ...      July 30 2011  approved      NaN   \n",
       "1  Strengthening Communities  ...  February 01 2011  approved      NaN   \n",
       "2  Strengthening Communities  ...   January 29 2011  approved      NaN   \n",
       "3  Strengthening Communities  ...     March 31 2012  approved      NaN   \n",
       "4                Environment  ...  February 05 2011  approved      NaN   \n",
       "\n",
       "   Longitude  Community Board Community Council  Census Tract  BIN  BBL NTA  \n",
       "0        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "1        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "2        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "3        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "4        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.115142Z",
     "start_time": "2020-02-16T17:50:53.110187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1, 2, 3, 4 or 5 as the answer\n"
     ]
    }
   ],
   "source": [
    "# Use 1,2,3,4 or 5 as parameter\n",
    "utils.identity_features_puzzle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the `hiking` dataset. There are several columns here that need encoding, one of which is the `Accessible` column, which needs to be encoded in order to be modeled. `Accessible` is a binary feature, so it has two values - either `Y` or `N` - so it needs to be encoded into 1s and 0s. We'll use scikit-learn's `LabelEncoder` method to do that transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.176974Z",
     "start_time": "2020-02-16T17:50:53.152073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prop_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Park_Name</th>\n",
       "      <th>Length</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Other_Details</th>\n",
       "      <th>Accessible</th>\n",
       "      <th>Limited_Access</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B057</td>\n",
       "      <td>Salt Marsh Nature Trail</td>\n",
       "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
       "      <td>Marine Park</td>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B073</td>\n",
       "      <td>Lullwater</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B073</td>\n",
       "      <td>Midwood</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Step back in time with a walk through Brooklyn...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B073</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Discover how the Peninsula has changed over th...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B073</td>\n",
       "      <td>Waterfall</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Trace the source of the Lake on the Waterfall ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prop_ID                     Name  \\\n",
       "0    B057  Salt Marsh Nature Trail   \n",
       "1    B073                Lullwater   \n",
       "2    B073                  Midwood   \n",
       "3    B073                Peninsula   \n",
       "4    B073                Waterfall   \n",
       "\n",
       "                                            Location      Park_Name  \\\n",
       "0  Enter behind the Salt Marsh Nature Center, loc...    Marine Park   \n",
       "1  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "2  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "3  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "4  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "\n",
       "       Length Difficulty                                      Other_Details  \\\n",
       "0   0.8 miles       None  <p>The first half of this mile-long trail foll...   \n",
       "1    1.0 mile       Easy  Explore the Lullwater to see how nature thrive...   \n",
       "2  0.75 miles       Easy  Step back in time with a walk through Brooklyn...   \n",
       "3   0.5 miles       Easy  Discover how the Peninsula has changed over th...   \n",
       "4   0.5 miles       Easy  Trace the source of the Lake on the Waterfall ...   \n",
       "\n",
       "  Accessible Limited_Access  lat  lon  \n",
       "0          Y              N  NaN  NaN  \n",
       "1          N              N  NaN  NaN  \n",
       "2          N              N  NaN  NaN  \n",
       "3          N              N  NaN  NaN  \n",
       "4          N              N  NaN  NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.hiking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.207913Z",
     "start_time": "2020-02-16T17:50:53.195923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.237842Z",
     "start_time": "2020-02-16T17:50:53.230890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the LabelEncoder object\n",
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.284720Z",
     "start_time": "2020-02-16T17:50:53.264771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the encoding to the \"Accessible\" column\n",
    "utils.hiking['Accessible_enc'] = enc.fit_transform(utils.hiking['Accessible'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.331627Z",
     "start_time": "2020-02-16T17:50:53.305695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessible</th>\n",
       "      <th>Accessible_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accessible  Accessible_enc\n",
       "0          Y               1\n",
       "1          N               0\n",
       "2          N               0\n",
       "3          N               0\n",
       "4          N               0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the two columns\n",
    "utils.hiking[['Accessible', 'Accessible_enc']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! `.fit_transform()` is a good way to both fit an encoding and transform the data in a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - one-hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the columns in the volunteer dataset, `category_desc`, gives category descriptions for the volunteer opportunities listed. Because it is a categorical variable with more than two categories, we need to use one-hot encoding to transform this column numerically. We'll use Pandas' `get_dummies()` function to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.362510Z",
     "start_time": "2020-02-16T17:50:53.345589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the category_desc column\n",
    "category_enc = pd.get_dummies(utils.volunteer['category_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.408386Z",
     "start_time": "2020-02-16T17:50:53.393459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>Emergency Preparedness</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Health</th>\n",
       "      <th>Helping Neighbors in Need</th>\n",
       "      <th>Strengthening Communities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  Emergency Preparedness  Environment  Health  \\\n",
       "0          0                       0            0       0   \n",
       "1          0                       0            0       0   \n",
       "2          0                       0            0       0   \n",
       "3          0                       0            0       0   \n",
       "4          0                       0            1       0   \n",
       "\n",
       "   Helping Neighbors in Need  Strengthening Communities  \n",
       "0                          0                          1  \n",
       "1                          0                          1  \n",
       "2                          0                          1  \n",
       "3                          0                          1  \n",
       "4                          0                          0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the encoded columns\n",
    "category_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dummies()` is a simple and quick way to encode categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering numerical features - taking an average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good use case for taking an aggregate statistic to create a new feature is to take the mean of columns. Here, we have a DataFrame of running times named `running_times_5k`. For each `name` in the dataset, take the mean of their 5 run times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.456261Z",
     "start_time": "2020-02-16T17:50:53.440332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>run1</th>\n",
       "      <th>run2</th>\n",
       "      <th>run3</th>\n",
       "      <th>run4</th>\n",
       "      <th>run5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sue</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark</td>\n",
       "      <td>16.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean</td>\n",
       "      <td>23.5</td>\n",
       "      <td>25.1</td>\n",
       "      <td>25.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erin</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>25.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>26.7</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Russell</td>\n",
       "      <td>30.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>29.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  run1  run2  run3  run4  run5\n",
       "0      Sue  20.1  18.5  19.6  20.3  18.3\n",
       "1     Mark  16.5  17.1  16.9  17.6  17.3\n",
       "2     Sean  23.5  25.1  25.2  24.6  23.9\n",
       "3     Erin  21.7  21.1  20.9  22.1  22.2\n",
       "4    Jenny  25.8  27.1  26.1  26.7  26.9\n",
       "5  Russell  30.9  29.6  31.4  30.4  29.9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.running_times_5k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.502137Z",
     "start_time": "2020-02-16T17:50:53.486212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of the columns to average\n",
    "run_columns = ['run1', 'run2', 'run3', 'run4', 'run5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.547024Z",
     "start_time": "2020-02-16T17:50:53.522130Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use apply to create a mean column\n",
    "utils.running_times_5k[\"mean\"] = utils.running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.591904Z",
     "start_time": "2020-02-16T17:50:53.564984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>run1</th>\n",
       "      <th>run2</th>\n",
       "      <th>run3</th>\n",
       "      <th>run4</th>\n",
       "      <th>run5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sue</td>\n",
       "      <td>20.1</td>\n",
       "      <td>18.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>19.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark</td>\n",
       "      <td>16.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sean</td>\n",
       "      <td>23.5</td>\n",
       "      <td>25.1</td>\n",
       "      <td>25.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>24.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erin</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jenny</td>\n",
       "      <td>25.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>26.7</td>\n",
       "      <td>26.9</td>\n",
       "      <td>26.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Russell</td>\n",
       "      <td>30.9</td>\n",
       "      <td>29.6</td>\n",
       "      <td>31.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>29.9</td>\n",
       "      <td>30.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  run1  run2  run3  run4  run5   mean\n",
       "0      Sue  20.1  18.5  19.6  20.3  18.3  19.36\n",
       "1     Mark  16.5  17.1  16.9  17.6  17.3  17.08\n",
       "2     Sean  23.5  25.1  25.2  24.6  23.9  24.46\n",
       "3     Erin  21.7  21.1  20.9  22.1  22.2  21.60\n",
       "4    Jenny  25.8  27.1  26.1  26.7  26.9  26.52\n",
       "5  Russell  30.9  29.6  31.4  30.4  29.9  30.44"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the results\n",
    "utils.running_times_5k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Lambdas are especially helpful for operating across columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering numerical features - datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several columns in the `volunteer` dataset comprised of datetimes. Let's take a look at the `start_date_date` column and extract just the month to use as a feature for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.623315Z",
     "start_time": "2020-02-16T17:50:53.605901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date_date</th>\n",
       "      <th>end_date_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>July 30 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>February 01 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>January 29 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 14 2011</td>\n",
       "      <td>March 31 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 05 2011</td>\n",
       "      <td>February 05 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_date_date     end_date_date\n",
       "0      July 30 2011      July 30 2011\n",
       "1  February 01 2011  February 01 2011\n",
       "2   January 29 2011   January 29 2011\n",
       "3  February 14 2011     March 31 2012\n",
       "4  February 05 2011  February 05 2011"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer[['start_date_date', 'end_date_date']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.717614Z",
     "start_time": "2020-02-16T17:50:53.646232Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, convert string column to date column\n",
    "utils.volunteer[\"start_date_converted\"] = pd.to_datetime(utils.volunteer[\"start_date_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.733573Z",
     "start_time": "2020-02-16T17:50:53.720576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date_date</th>\n",
       "      <th>start_date_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>2011-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>2011-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>2011-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 14 2011</td>\n",
       "      <td>2011-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 05 2011</td>\n",
       "      <td>2011-02-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_date_date start_date_converted\n",
       "0      July 30 2011           2011-07-30\n",
       "1  February 01 2011           2011-02-01\n",
       "2   January 29 2011           2011-01-29\n",
       "3  February 14 2011           2011-02-14\n",
       "4  February 05 2011           2011-02-05"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer[['start_date_date', 'start_date_converted']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.749530Z",
     "start_time": "2020-02-16T17:50:53.736534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract just the month from the converted column\n",
    "utils.volunteer['start_date_month'] = utils.volunteer['start_date_converted'].apply(lambda row: row.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.781445Z",
     "start_time": "2020-02-16T17:50:53.767475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date_date</th>\n",
       "      <th>start_date_converted</th>\n",
       "      <th>start_date_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>2011-07-30</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 14 2011</td>\n",
       "      <td>2011-02-14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 05 2011</td>\n",
       "      <td>2011-02-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start_date_date start_date_converted  start_date_month\n",
       "0      July 30 2011           2011-07-30                 7\n",
       "1  February 01 2011           2011-02-01                 2\n",
       "2   January 29 2011           2011-01-29                 1\n",
       "3  February 14 2011           2011-02-14                 2\n",
       "4  February 05 2011           2011-02-05                 2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the converted and new month columns\n",
    "utils.volunteer[['start_date_date', 'start_date_converted', 'start_date_month']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can also use attributes like `.day` to get the day and `.year` to get the year from datetime columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering features from strings - extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Length` column in the `hiking` dataset is a column of strings, but contained in the column is the mileage for the hike. We're going to extract this mileage using regular expressions, and then use a lambda in Pandas to apply the extraction to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.828802Z",
     "start_time": "2020-02-16T17:50:53.808390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prop_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Park_Name</th>\n",
       "      <th>Length</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Other_Details</th>\n",
       "      <th>Accessible</th>\n",
       "      <th>Limited_Access</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>Accessible_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B057</td>\n",
       "      <td>Salt Marsh Nature Trail</td>\n",
       "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
       "      <td>Marine Park</td>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B073</td>\n",
       "      <td>Lullwater</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B073</td>\n",
       "      <td>Midwood</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Step back in time with a walk through Brooklyn...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B073</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Discover how the Peninsula has changed over th...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B073</td>\n",
       "      <td>Waterfall</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Trace the source of the Lake on the Waterfall ...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prop_ID                     Name  \\\n",
       "0    B057  Salt Marsh Nature Trail   \n",
       "1    B073                Lullwater   \n",
       "2    B073                  Midwood   \n",
       "3    B073                Peninsula   \n",
       "4    B073                Waterfall   \n",
       "\n",
       "                                            Location      Park_Name  \\\n",
       "0  Enter behind the Salt Marsh Nature Center, loc...    Marine Park   \n",
       "1  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "2  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "3  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "4  Enter Park at Lincoln Road and Ocean Avenue en...  Prospect Park   \n",
       "\n",
       "       Length Difficulty                                      Other_Details  \\\n",
       "0   0.8 miles       None  <p>The first half of this mile-long trail foll...   \n",
       "1    1.0 mile       Easy  Explore the Lullwater to see how nature thrive...   \n",
       "2  0.75 miles       Easy  Step back in time with a walk through Brooklyn...   \n",
       "3   0.5 miles       Easy  Discover how the Peninsula has changed over th...   \n",
       "4   0.5 miles       Easy  Trace the source of the Lake on the Waterfall ...   \n",
       "\n",
       "  Accessible Limited_Access  lat  lon  Accessible_enc  \n",
       "0          Y              N  NaN  NaN               1  \n",
       "1          N              N  NaN  NaN               0  \n",
       "2          N              N  NaN  NaN               0  \n",
       "3          N              N  NaN  NaN               0  \n",
       "4          N              N  NaN  NaN               0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.hiking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.860740Z",
     "start_time": "2020-02-16T17:50:53.849745Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write a pattern to extract numbers and decimals\n",
    "import re\n",
    "\n",
    "def return_mileage(length):\n",
    "    if length is not None:\n",
    "        pattern = re.compile(r\"\\d+\\.\\d+\")\n",
    "\n",
    "        # Search the text for matches\n",
    "        mile = re.match(pattern, length)\n",
    "\n",
    "        # If a value is returned, use group(0) to return the found value\n",
    "        if mile is not None:\n",
    "            return float(mile.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.892629Z",
     "start_time": "2020-02-16T17:50:53.884668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the function to the Length column\n",
    "utils.hiking[\"Length_num\"] = utils.hiking[\"Length\"].apply(lambda row: return_mileage(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.938532Z",
     "start_time": "2020-02-16T17:50:53.923582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Length_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length  Length_num\n",
       "0   0.8 miles        0.80\n",
       "1    1.0 mile        1.00\n",
       "2  0.75 miles        0.75\n",
       "3   0.5 miles        0.50\n",
       "4   0.5 miles        0.50"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at both columns\n",
    "utils.hiking[[\"Length\", \"Length_num\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering features from strings - tf/idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the `volunteer` dataset's `title` column into a text vector, to use in a prediction task in the next example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:53.969457Z",
     "start_time": "2020-02-16T17:50:53.962470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take the title text\n",
    "title_text = utils.volunteer.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.016326Z",
     "start_time": "2020-02-16T17:50:54.001341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the vectorizer method\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.047251Z",
     "start_time": "2020-02-16T17:50:54.036279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the text into tf-idf vectors\n",
    "text_tfidf = tfidf_vec.fit_transform(title_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using tf/idf vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've encoded the`volunteer` dataset's `title` column into tf/idf vectors, let's use those vectors to try to predict the category_desc column. Notice that we have to run the `toarray()` method on the tf/idf vector, in order to get in it the proper format for scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.094127Z",
     "start_time": "2020-02-16T17:50:54.076165Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset according to the class distribution of category_desc\n",
    "y = utils.volunteer[\"category_desc\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tfidf.toarray(), y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.140003Z",
     "start_time": "2020-02-16T17:50:54.120024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Fit the model to the training data\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.187875Z",
     "start_time": "2020-02-16T17:50:54.160916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4431137724550898"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the model's accuracy\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Notice that the model doesn't score very well. We'll work on selecting the best features for modeling in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting features for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter goes over a few different techniques for selecting the most important features from the dataset. We'll learn how to drop redundant features, work with text vectors, and reduce the number of features in the dataset using principal component analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we had finished standardizing our data and creating new features. Which of the following scenarios is NOT a good candidate for feature selection?\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "1. Several columns of running times that have been averaged into a new column.\n",
    "2. A text field that hasn't been turned into a tf/idf vector yet.\n",
    "3. A column of text that has already had a float extracted out of it.\n",
    "4. A categorical field that has been one-hot encoded.\n",
    "5. The dataset contains columns related to whether something is a fruit or vegetable, the name of the fruit or vegetable, and the scientific name of the plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.219792Z",
     "start_time": "2020-02-16T17:50:54.205829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1, 2, 3, 4 or 5 as the answer\n"
     ]
    }
   ],
   "source": [
    "# Use 1,2,3,4 or 5 as parameter\n",
    "utils.feature_selction_puzzle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing redundant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting relevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's identify the redundant columns in the 'volunteer_processed' dataset and perform feature selection on the dataset to return a DataFrame of the relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we explore the volunteer dataset, we'll see three features which are related to location: `locality`, `region`, and `postalcode`. They contain repeated information, so it would make sense to keep only one of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.267662Z",
     "start_time": "2020-02-16T17:50:54.250707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locality</th>\n",
       "      <th>region</th>\n",
       "      <th>postalcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 22nd St\\nNew York, NY 10010\\n(40.74053152272...</td>\n",
       "      <td>NY</td>\n",
       "      <td>10010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>10026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>2114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>10455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>11372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1109 Fifth Avenue\\nNew York, NY 10128\\n(40.785...</td>\n",
       "      <td>NY</td>\n",
       "      <td>10128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>11201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>10020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>10010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            locality region  postalcode\n",
       "0                                                NaN     NY         NaN\n",
       "1  5 22nd St\\nNew York, NY 10010\\n(40.74053152272...     NY     10010.0\n",
       "2                                                NaN     NY     10026.0\n",
       "3                                                NaN     NY      2114.0\n",
       "4                                                NaN     NY     10455.0\n",
       "5                                                NaN     NY     11372.0\n",
       "6  1109 Fifth Avenue\\nNew York, NY 10128\\n(40.785...     NY     10128.0\n",
       "7                                                NaN     NY     11201.0\n",
       "8                                                NaN     NY     10020.0\n",
       "9                                                NaN     NY     10010.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer[['locality', 'region', 'postalcode']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also features that have gone through the feature engineering process: columns like 'Education' and 'Emergency Preparedness' are a product of encoding the categorical variable `category_desc`, so `category_desc` itself is redundant now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.313540Z",
     "start_time": "2020-02-16T17:50:54.297575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vol_requests</th>\n",
       "      <th>title</th>\n",
       "      <th>hits</th>\n",
       "      <th>category_desc</th>\n",
       "      <th>locality</th>\n",
       "      <th>region</th>\n",
       "      <th>postalcode</th>\n",
       "      <th>created_date</th>\n",
       "      <th>vol_requests_lognorm</th>\n",
       "      <th>created_month</th>\n",
       "      <th>Education</th>\n",
       "      <th>Emergency Preparedness</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Health</th>\n",
       "      <th>Helping Neighbors in Need</th>\n",
       "      <th>Strengthening Communities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Web designer</td>\n",
       "      <td>22</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>5 22nd St\\nNew York, NY 10010\\n(40.74053152272...</td>\n",
       "      <td>NY</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>2011-01-14</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
       "      <td>62</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>10026.0</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>Fight global hunger and support women farmers ...</td>\n",
       "      <td>14</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Stop 'N' Swap</td>\n",
       "      <td>31</td>\n",
       "      <td>Environment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>10455.0</td>\n",
       "      <td>2011-01-28</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Queens Stop 'N' Swap</td>\n",
       "      <td>135</td>\n",
       "      <td>Environment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>11372.0</td>\n",
       "      <td>2011-01-28</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vol_requests                                              title  hits  \\\n",
       "1             2                                       Web designer    22   \n",
       "2            20      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
       "3           500  Fight global hunger and support women farmers ...    14   \n",
       "4            15                                      Stop 'N' Swap    31   \n",
       "5            15                               Queens Stop 'N' Swap   135   \n",
       "\n",
       "               category_desc  \\\n",
       "1  Strengthening Communities   \n",
       "2  Strengthening Communities   \n",
       "3  Strengthening Communities   \n",
       "4                Environment   \n",
       "5                Environment   \n",
       "\n",
       "                                            locality region  postalcode  \\\n",
       "1  5 22nd St\\nNew York, NY 10010\\n(40.74053152272...     NY     10010.0   \n",
       "2                                                NaN     NY     10026.0   \n",
       "3                                                NaN     NY      2114.0   \n",
       "4                                                NaN     NY     10455.0   \n",
       "5                                                NaN     NY     11372.0   \n",
       "\n",
       "  created_date  vol_requests_lognorm  created_month  Education  \\\n",
       "1   2011-01-14              0.693147              1          0   \n",
       "2   2011-01-19              2.995732              1          0   \n",
       "3   2011-01-21              6.214608              1          0   \n",
       "4   2011-01-28              2.708050              1          0   \n",
       "5   2011-01-28              2.708050              1          0   \n",
       "\n",
       "   Emergency Preparedness  Environment  Health  Helping Neighbors in Need  \\\n",
       "1                       0            0       0                          0   \n",
       "2                       0            0       0                          0   \n",
       "3                       0            0       0                          0   \n",
       "4                       0            1       0                          0   \n",
       "5                       0            1       0                          0   \n",
       "\n",
       "   Strengthening Communities  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          0  \n",
       "5                          0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.volunteer_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.345422Z",
     "start_time": "2020-02-16T17:50:54.335477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 617 entries, 1 to 664\n",
      "Data columns (total 16 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   vol_requests               617 non-null    int64         \n",
      " 1   title                      617 non-null    object        \n",
      " 2   hits                       617 non-null    int64         \n",
      " 3   category_desc              617 non-null    object        \n",
      " 4   locality                   552 non-null    object        \n",
      " 5   region                     617 non-null    object        \n",
      " 6   postalcode                 612 non-null    float64       \n",
      " 7   created_date               617 non-null    datetime64[ns]\n",
      " 8   vol_requests_lognorm       617 non-null    float64       \n",
      " 9   created_month              617 non-null    int64         \n",
      " 10  Education                  617 non-null    uint8         \n",
      " 11  Emergency Preparedness     617 non-null    uint8         \n",
      " 12  Environment                617 non-null    uint8         \n",
      " 13  Health                     617 non-null    uint8         \n",
      " 14  Helping Neighbors in Need  617 non-null    uint8         \n",
      " 15  Strengthening Communities  617 non-null    uint8         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3), object(4), uint8(6)\n",
      "memory usage: 56.6+ KB\n"
     ]
    }
   ],
   "source": [
    "utils.volunteer_processed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.376340Z",
     "start_time": "2020-02-16T17:50:54.370385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of redundant column names to drop\n",
    "to_drop = [\"category_desc\", \"created_date\", \"locality\", \"region\", \"vol_requests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.423239Z",
     "start_time": "2020-02-16T17:50:54.403299Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop those columns from the dataset\n",
    "volunteer_subset = utils.volunteer_processed.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.471120Z",
     "start_time": "2020-02-16T17:50:54.447184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>hits</th>\n",
       "      <th>postalcode</th>\n",
       "      <th>vol_requests_lognorm</th>\n",
       "      <th>created_month</th>\n",
       "      <th>Education</th>\n",
       "      <th>Emergency Preparedness</th>\n",
       "      <th>Environment</th>\n",
       "      <th>Health</th>\n",
       "      <th>Helping Neighbors in Need</th>\n",
       "      <th>Strengthening Communities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Web designer</td>\n",
       "      <td>22</td>\n",
       "      <td>10010.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
       "      <td>62</td>\n",
       "      <td>10026.0</td>\n",
       "      <td>2.995732</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fight global hunger and support women farmers ...</td>\n",
       "      <td>14</td>\n",
       "      <td>2114.0</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop 'N' Swap</td>\n",
       "      <td>31</td>\n",
       "      <td>10455.0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Queens Stop 'N' Swap</td>\n",
       "      <td>135</td>\n",
       "      <td>11372.0</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  hits  postalcode  \\\n",
       "1                                       Web designer    22     10010.0   \n",
       "2      Urban Adventures - Ice Skating at Lasker Rink    62     10026.0   \n",
       "3  Fight global hunger and support women farmers ...    14      2114.0   \n",
       "4                                      Stop 'N' Swap    31     10455.0   \n",
       "5                               Queens Stop 'N' Swap   135     11372.0   \n",
       "\n",
       "   vol_requests_lognorm  created_month  Education  Emergency Preparedness  \\\n",
       "1              0.693147              1          0                       0   \n",
       "2              2.995732              1          0                       0   \n",
       "3              6.214608              1          0                       0   \n",
       "4              2.708050              1          0                       0   \n",
       "5              2.708050              1          0                       0   \n",
       "\n",
       "   Environment  Health  Helping Neighbors in Need  Strengthening Communities  \n",
       "1            0       0                          0                          1  \n",
       "2            0       0                          0                          1  \n",
       "3            0       0                          0                          1  \n",
       "4            1       0                          0                          0  \n",
       "5            1       0                          0                          0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the head of the new dataset\n",
    "volunteer_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the wine dataset again, which is made up of continuous, numerical features. We run Pearson's correlation coefficient on the dataset to determine which columns are good candidates for eliminating. Then, remove those columns from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.516995Z",
     "start_time": "2020-02-16T17:50:54.488042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328222</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.209179</td>\n",
       "      <td>-0.719163</td>\n",
       "      <td>-0.847498</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.788230</td>\n",
       "      <td>-0.633717</td>\n",
       "      <td>-0.569246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>-0.328222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>0.637325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>0.437776</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>-0.152643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>0.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>-0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>-0.209179</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.424006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>-0.719163</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.431205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>-0.847498</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>0.410494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>-0.275675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.290203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color intensity</th>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.348970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.173593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>-0.788230</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>0.254218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>-0.633717</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline_log</th>\n",
       "      <td>-0.569246</td>\n",
       "      <td>0.637325</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238394</td>\n",
       "      <td>-0.416897</td>\n",
       "      <td>0.424006</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>0.410494</td>\n",
       "      <td>-0.275675</td>\n",
       "      <td>0.290203</td>\n",
       "      <td>0.348970</td>\n",
       "      <td>0.173593</td>\n",
       "      <td>0.254218</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Type   Alcohol  Malic acid       Ash  \\\n",
       "Type                          1.000000 -0.328222    0.437776 -0.049643   \n",
       "Alcohol                      -0.328222  1.000000    0.094397  0.211545   \n",
       "Malic acid                    0.437776  0.094397    1.000000  0.164045   \n",
       "Ash                          -0.049643  0.211545    0.164045  1.000000   \n",
       "Alcalinity of ash             0.517859 -0.310235    0.288500  0.443367   \n",
       "Magnesium                    -0.209179  0.270798   -0.054575  0.286587   \n",
       "Total phenols                -0.719163  0.289101   -0.335167  0.128980   \n",
       "Flavanoids                   -0.847498  0.236815   -0.411007  0.115077   \n",
       "Nonflavanoid phenols          0.489109 -0.155929    0.292977  0.186230   \n",
       "Proanthocyanins              -0.499130  0.136698   -0.220746  0.009652   \n",
       "Color intensity               0.265668  0.546364    0.248985  0.258887   \n",
       "Hue                          -0.617369 -0.071747   -0.561296 -0.074667   \n",
       "OD280/OD315 of diluted wines -0.788230  0.072343   -0.368710  0.003911   \n",
       "Proline                      -0.633717  0.643720   -0.192011  0.223626   \n",
       "Proline_log                  -0.569246  0.637325   -0.152643  0.238394   \n",
       "\n",
       "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "Type                                   0.517859  -0.209179      -0.719163   \n",
       "Alcohol                               -0.310235   0.270798       0.289101   \n",
       "Malic acid                             0.288500  -0.054575      -0.335167   \n",
       "Ash                                    0.443367   0.286587       0.128980   \n",
       "Alcalinity of ash                      1.000000  -0.083333      -0.321113   \n",
       "Magnesium                             -0.083333   1.000000       0.214401   \n",
       "Total phenols                         -0.321113   0.214401       1.000000   \n",
       "Flavanoids                            -0.351370   0.195784       0.864564   \n",
       "Nonflavanoid phenols                   0.361922  -0.256294      -0.449935   \n",
       "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
       "Color intensity                        0.018732   0.199950      -0.055136   \n",
       "Hue                                   -0.273955   0.055398       0.433681   \n",
       "OD280/OD315 of diluted wines          -0.276769   0.066004       0.699949   \n",
       "Proline                               -0.440597   0.393351       0.498115   \n",
       "Proline_log                           -0.416897   0.424006       0.431205   \n",
       "\n",
       "                              Flavanoids  Nonflavanoid phenols  \\\n",
       "Type                           -0.847498              0.489109   \n",
       "Alcohol                         0.236815             -0.155929   \n",
       "Malic acid                     -0.411007              0.292977   \n",
       "Ash                             0.115077              0.186230   \n",
       "Alcalinity of ash              -0.351370              0.361922   \n",
       "Magnesium                       0.195784             -0.256294   \n",
       "Total phenols                   0.864564             -0.449935   \n",
       "Flavanoids                      1.000000             -0.537900   \n",
       "Nonflavanoid phenols           -0.537900              1.000000   \n",
       "Proanthocyanins                 0.652692             -0.365845   \n",
       "Color intensity                -0.172379              0.139057   \n",
       "Hue                             0.543479             -0.262640   \n",
       "OD280/OD315 of diluted wines    0.787194             -0.503270   \n",
       "Proline                         0.494193             -0.311385   \n",
       "Proline_log                     0.410494             -0.275675   \n",
       "\n",
       "                              Proanthocyanins  Color intensity       Hue  \\\n",
       "Type                                -0.499130         0.265668 -0.617369   \n",
       "Alcohol                              0.136698         0.546364 -0.071747   \n",
       "Malic acid                          -0.220746         0.248985 -0.561296   \n",
       "Ash                                  0.009652         0.258887 -0.074667   \n",
       "Alcalinity of ash                   -0.197327         0.018732 -0.273955   \n",
       "Magnesium                            0.236441         0.199950  0.055398   \n",
       "Total phenols                        0.612413        -0.055136  0.433681   \n",
       "Flavanoids                           0.652692        -0.172379  0.543479   \n",
       "Nonflavanoid phenols                -0.365845         0.139057 -0.262640   \n",
       "Proanthocyanins                      1.000000        -0.025250  0.295544   \n",
       "Color intensity                     -0.025250         1.000000 -0.521813   \n",
       "Hue                                  0.295544        -0.521813  1.000000   \n",
       "OD280/OD315 of diluted wines         0.519067        -0.428815  0.565468   \n",
       "Proline                              0.330417         0.316100  0.236183   \n",
       "Proline_log                          0.290203         0.348970  0.173593   \n",
       "\n",
       "                              OD280/OD315 of diluted wines   Proline  \\\n",
       "Type                                             -0.788230 -0.633717   \n",
       "Alcohol                                           0.072343  0.643720   \n",
       "Malic acid                                       -0.368710 -0.192011   \n",
       "Ash                                               0.003911  0.223626   \n",
       "Alcalinity of ash                                -0.276769 -0.440597   \n",
       "Magnesium                                         0.066004  0.393351   \n",
       "Total phenols                                     0.699949  0.498115   \n",
       "Flavanoids                                        0.787194  0.494193   \n",
       "Nonflavanoid phenols                             -0.503270 -0.311385   \n",
       "Proanthocyanins                                   0.519067  0.330417   \n",
       "Color intensity                                  -0.428815  0.316100   \n",
       "Hue                                               0.565468  0.236183   \n",
       "OD280/OD315 of diluted wines                      1.000000  0.312761   \n",
       "Proline                                           0.312761  1.000000   \n",
       "Proline_log                                       0.254218  0.977423   \n",
       "\n",
       "                              Proline_log  \n",
       "Type                            -0.569246  \n",
       "Alcohol                          0.637325  \n",
       "Malic acid                      -0.152643  \n",
       "Ash                              0.238394  \n",
       "Alcalinity of ash               -0.416897  \n",
       "Magnesium                        0.424006  \n",
       "Total phenols                    0.431205  \n",
       "Flavanoids                       0.410494  \n",
       "Nonflavanoid phenols            -0.275675  \n",
       "Proanthocyanins                  0.290203  \n",
       "Color intensity                  0.348970  \n",
       "Hue                              0.173593  \n",
       "OD280/OD315 of diluted wines     0.254218  \n",
       "Proline                          0.977423  \n",
       "Proline_log                      1.000000  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the column correlations of the wine dataset\n",
    "corr_matrix = utils.wine.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.546918Z",
     "start_time": "2020-02-16T17:50:54.534938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Proline_log                   Proline                         0.977423\n",
       "Proline                       Proline_log                     0.977423\n",
       "Total phenols                 Flavanoids                      0.864564\n",
       "Flavanoids                    Total phenols                   0.864564\n",
       "Type                          Flavanoids                      0.847498\n",
       "Flavanoids                    Type                            0.847498\n",
       "Type                          OD280/OD315 of diluted wines    0.788230\n",
       "OD280/OD315 of diluted wines  Type                            0.788230\n",
       "Flavanoids                    OD280/OD315 of diluted wines    0.787194\n",
       "OD280/OD315 of diluted wines  Flavanoids                      0.787194\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a minute to find the column where the correlation value is greater than 0.75 at least twice or run the following code\n",
    "corrs = corr_matrix.abs().unstack().sort_values(kind='quicksort', ascending=False)\n",
    "corrs[(corrs>0.75) & (corrs<1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.578800Z",
     "start_time": "2020-02-16T17:50:54.571849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flavanoids has high correlation with Total phenols and OD280/OD315 of diluted wines\n",
    "# Proline is already redundant because of Proline_log\n",
    "# We don't drop Type because it the target column\n",
    "to_drop = [\"Flavanoids\", \"Proline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.625675Z",
     "start_time": "2020-02-16T17:50:54.608726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>6.970730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>6.956545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>7.077498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>7.299797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>6.599870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0     1    14.23        1.71  2.43               15.6        127   \n",
       "1     1    13.20        1.78  2.14               11.2        100   \n",
       "2     1    13.16        2.36  2.67               18.6        101   \n",
       "3     1    14.37        1.95  2.50               16.8        113   \n",
       "4     1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Nonflavanoid phenols  Proanthocyanins  Color intensity  \\\n",
       "0           2.80                  0.28             2.29             5.64   \n",
       "1           2.65                  0.26             1.28             4.38   \n",
       "2           2.80                  0.30             2.81             5.68   \n",
       "3           3.85                  0.24             2.18             7.80   \n",
       "4           2.80                  0.39             1.82             4.32   \n",
       "\n",
       "    Hue  OD280/OD315 of diluted wines  Proline_log  \n",
       "0  1.04                          3.92     6.970730  \n",
       "1  1.05                          3.40     6.956545  \n",
       "2  1.03                          3.17     7.077498  \n",
       "3  0.86                          3.45     7.299797  \n",
       "4  1.04                          2.93     6.599870  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop that column from the DataFrame\n",
    "utils.wine = utils.wine.drop(to_drop, axis=1)\n",
    "utils.wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.672582Z",
     "start_time": "2020-02-16T17:50:54.648613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328222</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.209179</td>\n",
       "      <td>-0.719163</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.788230</td>\n",
       "      <td>-0.569246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>-0.328222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.637325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>0.437776</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.152643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>-0.209179</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.424006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>-0.719163</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.431205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.275675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.290203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color intensity</th>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.348970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.173593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>-0.788230</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline_log</th>\n",
       "      <td>-0.569246</td>\n",
       "      <td>0.637325</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238394</td>\n",
       "      <td>-0.416897</td>\n",
       "      <td>0.424006</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>-0.275675</td>\n",
       "      <td>0.290203</td>\n",
       "      <td>0.348970</td>\n",
       "      <td>0.173593</td>\n",
       "      <td>0.254218</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Type   Alcohol  Malic acid       Ash  \\\n",
       "Type                          1.000000 -0.328222    0.437776 -0.049643   \n",
       "Alcohol                      -0.328222  1.000000    0.094397  0.211545   \n",
       "Malic acid                    0.437776  0.094397    1.000000  0.164045   \n",
       "Ash                          -0.049643  0.211545    0.164045  1.000000   \n",
       "Alcalinity of ash             0.517859 -0.310235    0.288500  0.443367   \n",
       "Magnesium                    -0.209179  0.270798   -0.054575  0.286587   \n",
       "Total phenols                -0.719163  0.289101   -0.335167  0.128980   \n",
       "Nonflavanoid phenols          0.489109 -0.155929    0.292977  0.186230   \n",
       "Proanthocyanins              -0.499130  0.136698   -0.220746  0.009652   \n",
       "Color intensity               0.265668  0.546364    0.248985  0.258887   \n",
       "Hue                          -0.617369 -0.071747   -0.561296 -0.074667   \n",
       "OD280/OD315 of diluted wines -0.788230  0.072343   -0.368710  0.003911   \n",
       "Proline_log                  -0.569246  0.637325   -0.152643  0.238394   \n",
       "\n",
       "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "Type                                   0.517859  -0.209179      -0.719163   \n",
       "Alcohol                               -0.310235   0.270798       0.289101   \n",
       "Malic acid                             0.288500  -0.054575      -0.335167   \n",
       "Ash                                    0.443367   0.286587       0.128980   \n",
       "Alcalinity of ash                      1.000000  -0.083333      -0.321113   \n",
       "Magnesium                             -0.083333   1.000000       0.214401   \n",
       "Total phenols                         -0.321113   0.214401       1.000000   \n",
       "Nonflavanoid phenols                   0.361922  -0.256294      -0.449935   \n",
       "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
       "Color intensity                        0.018732   0.199950      -0.055136   \n",
       "Hue                                   -0.273955   0.055398       0.433681   \n",
       "OD280/OD315 of diluted wines          -0.276769   0.066004       0.699949   \n",
       "Proline_log                           -0.416897   0.424006       0.431205   \n",
       "\n",
       "                              Nonflavanoid phenols  Proanthocyanins  \\\n",
       "Type                                      0.489109        -0.499130   \n",
       "Alcohol                                  -0.155929         0.136698   \n",
       "Malic acid                                0.292977        -0.220746   \n",
       "Ash                                       0.186230         0.009652   \n",
       "Alcalinity of ash                         0.361922        -0.197327   \n",
       "Magnesium                                -0.256294         0.236441   \n",
       "Total phenols                            -0.449935         0.612413   \n",
       "Nonflavanoid phenols                      1.000000        -0.365845   \n",
       "Proanthocyanins                          -0.365845         1.000000   \n",
       "Color intensity                           0.139057        -0.025250   \n",
       "Hue                                      -0.262640         0.295544   \n",
       "OD280/OD315 of diluted wines             -0.503270         0.519067   \n",
       "Proline_log                              -0.275675         0.290203   \n",
       "\n",
       "                              Color intensity       Hue  \\\n",
       "Type                                 0.265668 -0.617369   \n",
       "Alcohol                              0.546364 -0.071747   \n",
       "Malic acid                           0.248985 -0.561296   \n",
       "Ash                                  0.258887 -0.074667   \n",
       "Alcalinity of ash                    0.018732 -0.273955   \n",
       "Magnesium                            0.199950  0.055398   \n",
       "Total phenols                       -0.055136  0.433681   \n",
       "Nonflavanoid phenols                 0.139057 -0.262640   \n",
       "Proanthocyanins                     -0.025250  0.295544   \n",
       "Color intensity                      1.000000 -0.521813   \n",
       "Hue                                 -0.521813  1.000000   \n",
       "OD280/OD315 of diluted wines        -0.428815  0.565468   \n",
       "Proline_log                          0.348970  0.173593   \n",
       "\n",
       "                              OD280/OD315 of diluted wines  Proline_log  \n",
       "Type                                             -0.788230    -0.569246  \n",
       "Alcohol                                           0.072343     0.637325  \n",
       "Malic acid                                       -0.368710    -0.152643  \n",
       "Ash                                               0.003911     0.238394  \n",
       "Alcalinity of ash                                -0.276769    -0.416897  \n",
       "Magnesium                                         0.066004     0.424006  \n",
       "Total phenols                                     0.699949     0.431205  \n",
       "Nonflavanoid phenols                             -0.503270    -0.275675  \n",
       "Proanthocyanins                                   0.519067     0.290203  \n",
       "Color intensity                                  -0.428815     0.348970  \n",
       "Hue                                               0.565468     0.173593  \n",
       "OD280/OD315 of diluted wines                      1.000000     0.254218  \n",
       "Proline_log                                       0.254218     1.000000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.wine.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features using text vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text vectors, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's expand on the text vector exploration method we just learned about, using the `volunteer` dataset's title tf/idf vectors. In this first part of text vector exploration, we're going to add to that function we learned about above. We'll return a list of numbers with the function. In the next example, we'll write another function to collect the top words across all documents, extract them, and then use that list to filter down our `text_tfidf` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.704496Z",
     "start_time": "2020-02-16T17:50:54.690524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add in the rest of the parameters\n",
    "def return_weights(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
    "    \n",
    "    # Let's transform that zipped dict into a series\n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    \n",
    "    # Let's sort the series to pull out the top n weighted words\n",
    "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    return [original_vocab[i] for i in zipped_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.751338Z",
     "start_time": "2020-02-16T17:50:54.733388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[188, 23, 562]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the weighted words\n",
    "vocab = {v:k for k,v in tfidf_vec.vocabulary_.items()}\n",
    "return_weights(vocab, tfidf_vec.vocabulary_, text_tfidf, 8, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text vectors, part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the function we wrote in the previous exercise, we're going to extract the top words from each document in the text vector, return a list of the word indices, and use that list to filter the text vector down to those top words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:54.782281Z",
     "start_time": "2020-02-16T17:50:54.775300Z"
    }
   },
   "outputs": [],
   "source": [
    "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "    \n",
    "        # Here we'll call the function from the previous exercise, and extend the list we're creating\n",
    "        filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "    # Return the list in a set, so we don't get duplicate word indices\n",
    "    return set(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.438565Z",
     "start_time": "2020-02-16T17:50:54.813205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the function to get the list of word indices\n",
    "filtered_words = words_to_filter(vocab, tfidf_vec.vocabulary_, text_tfidf, 3)\n",
    "\n",
    "# By converting filtered_words back to a list, we can use it to filter the columns in the text vector\n",
    "filtered_text = text_tfidf[:, list(filtered_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Naive Bayes with feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-run the Naive Bayes text classification model we ran at the end of chapter 3, with our selection choices from the previous exercise, on the `volunteer` dataset's `title` and `category_desc` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.454521Z",
     "start_time": "2020-02-16T17:50:55.440541Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset according to the class distribution of category_desc\n",
    "y = utils.volunteer[\"category_desc\"]\n",
    "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.486408Z",
     "start_time": "2020-02-16T17:50:55.456488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "nb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.516365Z",
     "start_time": "2020-02-16T17:50:55.488370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4491017964071856"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the model's accuracy\n",
    "nb.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our accuracy score wasn't that different from the score at the end of chapter 3. That's okay; the title field is a very small text field, appropriate for demonstrating how filtering vectors works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply PCA to the wine dataset, to see if we can get an increase in our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.531353Z",
     "start_time": "2020-02-16T17:50:55.517331Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.547307Z",
     "start_time": "2020-02-16T17:50:55.533324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "pca = PCA()\n",
    "wine_X = utils.wine.drop(\"Type\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.562243Z",
     "start_time": "2020-02-16T17:50:55.548303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.577234Z",
     "start_time": "2020-02-16T17:50:55.566235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.12755402e-01, 5.09141191e-02, 2.48693943e-02, 5.09461731e-03,\n",
       "       3.21347706e-03, 1.45045542e-03, 6.41602177e-04, 4.34299470e-04,\n",
       "       3.29772489e-04, 1.61719100e-04, 9.54355350e-05, 3.97060700e-05])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the percentage of variance explained by the different components\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section you'll train a model using the PCA-transformed vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have run PCA on the `wine` dataset, let's try training a model with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.592191Z",
     "start_time": "2020-02-16T17:50:55.580198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the transformed X and the y labels into training and test sets\n",
    "wine_y = utils.wine[\"Type\"]\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X, wine_y, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.608120Z",
     "start_time": "2020-02-16T17:50:55.595153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit knn to the training data\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_wine_train, y_wine_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.623080Z",
     "start_time": "2020-02-16T17:50:55.611110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8444444444444444"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score knn on the test data and print it out\n",
    "knn.score(X_wine_test, y_wine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've learned all about preprocessing we'll try these techniques out on a dataset that records information on UFO sightings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFOs and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking column types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the UFO dataset's column types using the `dtypes` attribute. One column jumps out for transformation: the `date` column, which can be transformed into the `datetime` type. That will make our feature engineering efforts easier later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.669462Z",
     "start_time": "2020-02-16T17:50:55.626070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/3/2011 19:21</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.953056</td>\n",
       "      <td>-92.291111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2004 19:05</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.499444</td>\n",
       "      <td>-81.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/25/2009 21:00</td>\n",
       "      <td>coon rapids</td>\n",
       "      <td>mn</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
       "      <td>12/12/2009</td>\n",
       "      <td>45.120000</td>\n",
       "      <td>-93.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/21/2002 05:45</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.021389</td>\n",
       "      <td>-80.382222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/19/2010 12:55</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date              city state country      type    seconds  \\\n",
       "0   11/3/2011 19:21         woodville    wi      us   unknown  1209600.0   \n",
       "1   10/3/2004 19:05         cleveland    oh      us    circle       30.0   \n",
       "2   9/25/2009 21:00       coon rapids    mn      us     cigar        0.0   \n",
       "3  11/21/2002 05:45          clemmons    nc      us  triangle      300.0   \n",
       "4   8/19/2010 12:55  calgary (canada)    ab      ca      oval        0.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "2              NaN  Green&#44 red&#44 and blue pulses of light tha...   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "\n",
       "     recorded        lat        long  \n",
       "0  12/12/2011  44.953056  -92.291111  \n",
       "1  10/27/2004  41.499444  -81.695556  \n",
       "2  12/12/2009  45.120000  -93.287500  \n",
       "3  12/23/2002  36.021389  -80.382222  \n",
       "4   8/24/2010  51.083333 -114.083333  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo = pd.read_csv('data/ufo_sightings_large.csv')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:55.685420Z",
     "start_time": "2020-02-16T17:50:55.671459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               object\n",
       "city               object\n",
       "state              object\n",
       "country            object\n",
       "type               object\n",
       "seconds           float64\n",
       "length_of_time     object\n",
       "desc               object\n",
       "recorded           object\n",
       "lat               float64\n",
       "long              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.091209Z",
     "start_time": "2020-02-16T17:50:55.687414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the date column to type datetime\n",
    "ufo[\"date\"] = pd.to_datetime(ufo[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove some of the rows where certain columns have missing values. We're going to look at the `length_of_time column`, the `state` column, and the `type` column. If any of the values in these columns are missing, we're going to drop the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.107200Z",
     "start_time": "2020-02-16T17:50:56.093204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4935 entries, 0 to 4934\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   date            4935 non-null   datetime64[ns]\n",
      " 1   city            4926 non-null   object        \n",
      " 2   state           4516 non-null   object        \n",
      " 3   country         4255 non-null   object        \n",
      " 4   type            4783 non-null   object        \n",
      " 5   seconds         4935 non-null   float64       \n",
      " 6   length_of_time  4791 non-null   object        \n",
      " 7   desc            4935 non-null   object        \n",
      " 8   recorded        4935 non-null   object        \n",
      " 9   lat             4935 non-null   float64       \n",
      " 10  long            4935 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(7)\n",
      "memory usage: 424.2+ KB\n"
     ]
    }
   ],
   "source": [
    "ufo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.122162Z",
     "start_time": "2020-02-16T17:50:56.109163Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length_of_time    144\n",
       "state             419\n",
       "type              152\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many values are missing in the length_of_time, state, and type columns\n",
    "ufo[['length_of_time', 'state', 'type']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.138110Z",
     "start_time": "2020-02-16T17:50:56.124146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only rows where length_of_time, state, and type are not null\n",
    "ufo = ufo[ufo[\"length_of_time\"].notnull() & ufo[\"state\"].notnull() & ufo[\"type\"].notnull()]\n",
    "ufo.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.154063Z",
     "start_time": "2020-02-16T17:50:56.141076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4286 entries, 0 to 4285\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   date            4286 non-null   datetime64[ns]\n",
      " 1   city            4283 non-null   object        \n",
      " 2   state           4286 non-null   object        \n",
      " 3   country         3891 non-null   object        \n",
      " 4   type            4286 non-null   object        \n",
      " 5   seconds         4286 non-null   float64       \n",
      " 6   length_of_time  4286 non-null   object        \n",
      " 7   desc            4286 non-null   object        \n",
      " 8   recorded        4286 non-null   object        \n",
      " 9   lat             4286 non-null   float64       \n",
      " 10  long            4286 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(7)\n",
      "memory usage: 368.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print out the shape of the new dataset\n",
    "ufo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables and standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting numbers from strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `length_of_time` field in the UFO dataset is a text field that has the number of minutes within the string. Here, we'll extract that number from that text field using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.170027Z",
     "start_time": "2020-02-16T17:50:56.158033Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def return_minutes(time_string):\n",
    "    # We'll use \\d+ to grab digits and match it to the column values\n",
    "    #pattern = re.compile(r\"(?:[^0-9]*)?(\\d+)(?:[^0-9]*)?(?:\\d*?)(?:minutes*|mins*)(?:[^0-9]*)?\")\n",
    "    #pattern = re.compile(r\"(\\d+)(?:[^0-9]*)?(?:minutes*|mins*)|(\\d+):(?:\\d*?)\")\n",
    "    pattern = re.compile(r\"(\\d+|\\d{1,2}\\.\\d{1,2})(?:[^0-9\\.]*)?(?:minutes*|mins*)|(\\d+):(?:\\d*?)\")    \n",
    "        \n",
    "    # Use match on the pattern and column\n",
    "    num = re.search(pattern, time_string)\n",
    "    if num is not None:\n",
    "        return math.floor(float((num.group(1) if num.group(1) is not None else num.group(2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.199953Z",
     "start_time": "2020-02-16T17:50:56.171995Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the extraction to the length_of_time column\n",
    "ufo[\"minutes\"] = ufo[\"length_of_time\"].apply(return_minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.215879Z",
     "start_time": "2020-02-16T17:50:56.201915Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 weeks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30sec.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 minutes</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total? maybe around 10 mi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>several sightings from 10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2 minutes</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 minutes</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5 minutes</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              length_of_time  minutes\n",
       "0                    2 weeks      NaN\n",
       "1                     30sec.      NaN\n",
       "2            about 5 minutes      5.0\n",
       "3                          2      NaN\n",
       "4                 10 minutes     10.0\n",
       "5  total? maybe around 10 mi      NaN\n",
       "6  several sightings from 10      NaN\n",
       "7                  2 minutes      2.0\n",
       "8                  2 minutes      2.0\n",
       "9                  5 minutes      5.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the head of both of the columns\n",
    "ufo[[\"length_of_time\", \"minutes\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we end up with some NaNs in the DataFrame. That's okay for now; we'll take care of those before modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.231858Z",
     "start_time": "2020-02-16T17:50:56.217876Z"
    }
   },
   "outputs": [],
   "source": [
    "ufo = ufo[(ufo['seconds'] != 0.0) & ufo['minutes'].notnull()]\n",
    "ufo.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying features for standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll investigate the variance of columns in the UFO dataset to determine which features should be standardized. After taking a look at the variances of the `seconds` and `minutes` column, we'll see that the variance of the seconds column is extremely high. Because `seconds` and `minutes` are related to each other (an issue we'll deal with when we select features for modeling), let's log normlize the `seconds` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.263782Z",
     "start_time": "2020-02-16T17:50:56.233830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seconds    602178.956602\n",
       "lat            42.263663\n",
       "long          402.268639\n",
       "minutes       127.066623\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the variance of the columns\n",
    "ufo.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.279738Z",
     "start_time": "2020-02-16T17:50:56.265748Z"
    }
   },
   "outputs": [],
   "source": [
    "# Log normalize the seconds column\n",
    "ufo[\"seconds_log\"] = np.log(ufo[\"seconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.295667Z",
     "start_time": "2020-02-16T17:50:56.281702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1970634438022885\n"
     ]
    }
   ],
   "source": [
    "# Print out the variance of just the seconds_log column\n",
    "print(ufo[\"seconds_log\"].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are couple of columns in the UFO dataset that need to be encoded before they can be modeled through scikit-learn. We'll do that transformation here, using both binary and one-hot encoding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.310663Z",
     "start_time": "2020-02-16T17:50:56.296695Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use Pandas to encode us values as 1 and others as 0\n",
    "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda val: 1 if val == \"us\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.326581Z",
     "start_time": "2020-02-16T17:50:56.312619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Print the number of unique type values\n",
    "print(len(ufo[\"type\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.341574Z",
     "start_time": "2020-02-16T17:50:56.329575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a one-hot encoded set of the type values\n",
    "type_set = pd.get_dummies(ufo[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.357523Z",
     "start_time": "2020-02-16T17:50:56.344532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate this set back to the ufo DataFrame\n",
    "ufo = pd.concat([ufo, type_set], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.389447Z",
     "start_time": "2020-02-16T17:50:56.359495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>flash</th>\n",
       "      <th>formation</th>\n",
       "      <th>light</th>\n",
       "      <th>other</th>\n",
       "      <th>oval</th>\n",
       "      <th>rectangle</th>\n",
       "      <th>sphere</th>\n",
       "      <th>teardrop</th>\n",
       "      <th>triangle</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.021389</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-06-16 23:00:00</td>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Dancing lights that would fly around and then ...</td>\n",
       "      <td>7/4/2012</td>\n",
       "      <td>32.715278</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-09 00:00:00</td>\n",
       "      <td>oakville (canada)</td>\n",
       "      <td>on</td>\n",
       "      <td>ca</td>\n",
       "      <td>light</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Brilliant orange light or chinese lantern at o...</td>\n",
       "      <td>7/3/2013</td>\n",
       "      <td>43.433333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-26 23:27:00</td>\n",
       "      <td>lacey</td>\n",
       "      <td>wa</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2 minutes</td>\n",
       "      <td>Bright red light moving north to north west fr...</td>\n",
       "      <td>5/15/2013</td>\n",
       "      <td>47.034444</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-09-13 20:30:00</td>\n",
       "      <td>ben avon</td>\n",
       "      <td>pa</td>\n",
       "      <td>us</td>\n",
       "      <td>sphere</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>North-east moving south-west. First 7 or so li...</td>\n",
       "      <td>9/30/2013</td>\n",
       "      <td>40.508056</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date               city state country      type  seconds  \\\n",
       "0 2002-11-21 05:45:00           clemmons    nc      us  triangle    300.0   \n",
       "1 2012-06-16 23:00:00          san diego    ca      us     light    600.0   \n",
       "2 2013-06-09 00:00:00  oakville (canada)    on      ca     light    120.0   \n",
       "3 2013-04-26 23:27:00              lacey    wa      us     light    120.0   \n",
       "4 2013-09-13 20:30:00           ben avon    pa      us    sphere    300.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "1       10 minutes  Dancing lights that would fly around and then ...   \n",
       "2        2 minutes  Brilliant orange light or chinese lantern at o...   \n",
       "3        2 minutes  Bright red light moving north to north west fr...   \n",
       "4        5 minutes  North-east moving south-west. First 7 or so li...   \n",
       "\n",
       "     recorded        lat  ...  flash  formation  light  other  oval  \\\n",
       "0  12/23/2002  36.021389  ...      0          0      0      0     0   \n",
       "1    7/4/2012  32.715278  ...      0          0      1      0     0   \n",
       "2    7/3/2013  43.433333  ...      0          0      1      0     0   \n",
       "3   5/15/2013  47.034444  ...      0          0      1      0     0   \n",
       "4   9/30/2013  40.508056  ...      0          0      0      0     0   \n",
       "\n",
       "   rectangle  sphere  teardrop  triangle  unknown  \n",
       "0          0       0         0         1        0  \n",
       "1          0       0         0         0        0  \n",
       "2          0       0         0         0        0  \n",
       "3          0       0         0         0        0  \n",
       "4          0       1         0         0        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another feature engineering task to perform is month and year extraction. We'll perform this task on the `date` column of the `ufo` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.405397Z",
     "start_time": "2020-02-16T17:50:56.391427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2002-11-21 05:45:00\n",
       "1   2012-06-16 23:00:00\n",
       "2   2013-06-09 00:00:00\n",
       "3   2013-04-26 23:27:00\n",
       "4   2013-09-13 20:30:00\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 5 rows of the date column\n",
    "ufo[\"date\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.421360Z",
     "start_time": "2020-02-16T17:50:56.407367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the month from the date column\n",
    "ufo[\"month\"] = ufo[\"date\"].apply(lambda row: row.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.437286Z",
     "start_time": "2020-02-16T17:50:56.426317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the year from the date column\n",
    "ufo[\"year\"] = ufo[\"date\"].apply(lambda row: row.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.453275Z",
     "start_time": "2020-02-16T17:50:56.440278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>11</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-06-16 23:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-09 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-04-26 23:27:00</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-09-13 20:30:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  month  year\n",
       "0 2002-11-21 05:45:00     11  2002\n",
       "1 2012-06-16 23:00:00      6  2012\n",
       "2 2013-06-09 00:00:00      6  2013\n",
       "3 2013-04-26 23:27:00      4  2013\n",
       "4 2013-09-13 20:30:00      9  2013"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the head of all three columns\n",
    "ufo[[\"date\", \"month\", \"year\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform the `desc` column in the UFO dataset into tf/idf vectors, since there's likely something we can learn from this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.469225Z",
     "start_time": "2020-02-16T17:50:56.456234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    It was a large&#44 triangular shaped flying ob...\n",
       "1    Dancing lights that would fly around and then ...\n",
       "2    Brilliant orange light or chinese lantern at o...\n",
       "3    Bright red light moving north to north west fr...\n",
       "4    North-east moving south-west. First 7 or so li...\n",
       "Name: desc, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the head of the desc field\n",
    "ufo[\"desc\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.485157Z",
     "start_time": "2020-02-16T17:50:56.471195Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the tfidf vectorizer object\n",
    "vec = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.532060Z",
     "start_time": "2020-02-16T17:50:56.487151Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use vec's fit_transform method on the desc field\n",
    "desc_tfidf = vec.fit_transform(ufo[\"desc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.547017Z",
     "start_time": "2020-02-16T17:50:56.533031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2530, 4195)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the number of columns this creates.\n",
    "desc_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text vector has a large number of columns. We'll work on selecting the features we want to use for modeling in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the ideal dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get rid of some of the unnecessary features. Because we have an encoded country column, `country_enc`, we keep it and drop other columns related to location: `city`, `country`, `lat`, `long`, `state`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have columns related to `month` and `year`, so we don't need the `date` or `recorded` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vectorized `desc`, so we don't need it anymore. For now we'll keep `type`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep `seconds_log` and drop `seconds` and `minutes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also get rid of the `length_of_time` column, which is unnecessary after extracting `minutes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.561977Z",
     "start_time": "2020-02-16T17:50:56.548987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds</th>\n",
       "      <th>seconds_log</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seconds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804909</td>\n",
       "      <td>0.903248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_log</th>\n",
       "      <td>0.804909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.836148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes</th>\n",
       "      <td>0.903248</td>\n",
       "      <td>0.836148</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              seconds  seconds_log   minutes\n",
       "seconds      1.000000     0.804909  0.903248\n",
       "seconds_log  0.804909     1.000000  0.836148\n",
       "minutes      0.903248     0.836148  1.000000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
    "ufo[[\"seconds\", \"seconds_log\", \"minutes\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.577936Z",
     "start_time": "2020-02-16T17:50:56.563947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a list of features to drop   \n",
    "to_drop = [\"city\", \"country\", \"date\", \"desc\", \"lat\", \"length_of_time\", \"long\", \"minutes\", \"recorded\", \"seconds\", \"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:56.592896Z",
     "start_time": "2020-02-16T17:50:56.580905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop those features\n",
    "ufo = ufo.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:58.966940Z",
     "start_time": "2020-02-16T17:50:56.604840Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's also filter some words out of the text vector we created\n",
    "vocab = {v:k for k,v in vec.vocabulary_.items()}\n",
    "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done. In the next examples, we'll try modeling the UFO data in a couple of different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the UFO dataset, part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we're going to build a k-nearest neighbor model to predict which country the UFO sighting took place in. Our `X` dataset has the log-normalized seconds column, the one-hot encoded type columns, as well as the month and year when the sighting took place. The `y` labels are the encoded country column, where 1 is `us` and 0 is `ca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:58.982898Z",
     "start_time": "2020-02-16T17:50:58.969932Z"
    }
   },
   "outputs": [],
   "source": [
    "X = ufo.drop(['type', 'country_enc'], axis=1)\n",
    "y = ufo['country_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:58.997882Z",
     "start_time": "2020-02-16T17:50:58.985888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seconds_log', 'changing', 'chevron', 'cigar', 'circle', 'cone',\n",
       "       'cross', 'cylinder', 'diamond', 'disk', 'egg', 'fireball', 'flash',\n",
       "       'formation', 'light', 'other', 'oval', 'rectangle', 'sphere',\n",
       "       'teardrop', 'triangle', 'unknown', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the features in the X set of data\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:59.013846Z",
     "start_time": "2020-02-16T17:50:59.000848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the X and y sets using train_test_split, setting stratify=y\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:59.043760Z",
     "start_time": "2020-02-16T17:50:59.016821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:59.074661Z",
     "start_time": "2020-02-16T17:50:59.045742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8562401263823065\n"
     ]
    }
   ],
   "source": [
    "# Print the score of knn on the test sets\n",
    "print(knn.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome work! This model performs pretty well. It seems like we've made pretty good feature selection choices here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the UFO dataset, part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's build a model using the text vector we created, `desc_tfidf`, using the `filtered_words` list to create a filtered text vector. Let's see if we can predict the `type` of the sighting based on the text. We'll use a Naive Bayes model for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:59.089637Z",
     "start_time": "2020-02-16T17:50:59.077644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the list of filtered words we created to filter the text vector\n",
    "filtered_text = desc_tfidf[:, list(filtered_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:59.183039Z",
     "start_time": "2020-02-16T17:50:59.093603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split the X and y sets using train_test_split, setting stratify=y\n",
    "y = ufo['type']\n",
    "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:50:59.336664Z",
     "start_time": "2020-02-16T17:50:59.185032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit nb to the training sets\n",
    "nb.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T17:51:00.037493Z",
     "start_time": "2020-02-16T17:50:59.338624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1769352290679305"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the score of nb on the test sets\n",
    "nb.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this model performs very poorly on this text data. This is a clear case where iteration would be necessary to figure out what subset of text improves the model, and if perhaps any of the other features are useful in predicting `type`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "393.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
